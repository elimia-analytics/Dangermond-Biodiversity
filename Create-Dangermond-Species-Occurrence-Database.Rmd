---
title: "Create Dangermond Biodiversity Portal"
output: html_document
date: "2024-08-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Install and load required packages
```{r setup}
## Identify required package names
### CRAN packages
cran_packages <- c("tidyverse", "sf", "tmap", "spocc", "rinat", "ebirdst", "dataone", "sbtools", "tigris", "natserv")
### GitHub packages
github_packages <- c("gbifdb", "esri2sf")
## Install CRAN packages not yet installed
installed_cran_packages <- cran_packages %in% rownames(installed.packages())
if (any(installed_cran_packages == FALSE)) {
  install.packages(cran_packages[!installed_cran_packages])
}
## Install GitHub packages not yet installed
if (!("gbifdb" %in% rownames(installed.packages()))) devtools::install_github("ropensci/gbifdb")
if (!("esri2sf" %in% rownames(installed.packages()))) devtools::install_github("yonghah/esri2sf")
## Load all packages
invisible(lapply(c(cran_packages, github_packages), library, character.only = TRUE))
```

# Create directory to store data files
```{r, include = FALSE, echo = FALSE}
dir.create("data")
```

# Get GIS boundary layers for target areas
## Get Dangermond Preserve boundary
```{r, include = FALSE, echo = FALSE}
dangermond_preserve <- esri2sf::esri2sf("https://services.arcgis.com/F7DSX1DSNSiWmOqh/arcgis/rest/services/jldp_boundary/FeatureServer/2")
dangermond_preserve_wkt <- dangermond_preserve %>% sf::st_as_sfc() %>%  sf::st_as_text()
dangermond_preserve_bbox <- sf::st_bbox(dangermond_preserve) %>% sf::st_as_sfc() %>%  sf::st_as_text()
```

## Get Santa Barbara county boundary
```{r, include = FALSE, echo = FALSE}
sb_county <- tigris::counties("California", cb = TRUE) %>% 
  dplyr::filter(NAME %in% c("Santa Barbara")) %>% # , "San Luis Obispo", "Ventura")) %>% # In case more counties are needed
  sf::st_union()
sb_county_wkt <- sb_county %>%  sf::st_as_text()
sb_county_bbox <- sf::st_bbox(sb_county) %>% sf::st_as_sfc() %>%  sf::st_as_text()
```


# Get species occurrence data
## GBIF
```{r, include = FALSE, echo = FALSE}
## Extract GBIF occurrences for the Dangermond Preserve only
gbif_occurrence_count_dangermond <- spocc::occ(from = "gbif", limit = 1, geometry = dangermond_preserve_bbox, has_coords = TRUE)$gbif$meta$found
gbif_occurrences_dangermond <- spocc::occ(from = "gbif", limit = gbif_occurrence_count_dangermond, geometry = dangermond_preserve_bbox, date = c("1980-01-01", Sys.Date() %>% as.character()), has_coords = TRUE, )$gbif$data[[1]]
### Save output as csv
gbif_occurrences_dangermond %>% readr::write_csv("data/gbif_occurrences_dangermond.csv")

## Extract GBIF occurrences for Santa Barbara County using R package gbifdb (faster than SPOCC)
gbif_data <- gbifdb::gbif_remote(backend = "duckdb")
### Filter and download data
gbif_occurrences_california <- gbif_data %>% 
  dplyr::filter(stateprovince == "California")
gbif_occurrences_sb <- gbif_occurrences_california %>% 
  dplyr::filter(decimallongitude >= -120.6723 & decimallongitude <= -119.0274 & decimallatitude >= 33.46569 & decimallatitude <= 35.11459, year >= 1980) %>% # Limit to Santa Barbara County bounding box 
  dplyr::filter(!(basisofrecord %in% c("FOSSIL_SPECIMEN", "LIVING_SPECIMEN", "MATERIAL_SAMPLE"))) # Exclude
      if ("occurrencestatus" %in% colnames(gbif_occurrences_sb)) gbif_occurrences_sb <- gbif_occurrences_sb %>% dplyr::filter(occurrencestatus == "PRESENT")
      if ("coordinateuncertaintyinmeters" %in% colnames(gbif_occurrences_sb)) gbif_occurrences_sb <- gbif_occurrences_sb %>% dplyr::filter(!coordinateuncertaintyinmeters %in% c(999, 9999))
      if ("samplingprotocol" %in% colnames(gbif_occurrences_sb)) gbif_occurrences_sb <- gbif_occurrences_sb %>% dplyr::filter(!samplingprotocol %in% c("from a cultivated plant of known (indirect) wild origin", "grown"))
      if ("georeferenceremarks" %in% colnames(gbif_occurrences_sb)) gbif_occurrences_sb <- gbif_occurrences_sb %>% dplyr::filter(!grepl("centroid|Centroid|CENTROID", georeferenceremarks))

### Write out dataset based on filters
gbif_occurrences_sb <- gbif_occurrences_sb %>% 
  dplyr::mutate(geometry = st_point(decimallongitude, decimallatitude)) %>%
  duckdbfs::to_sf(crs = 4326)
### Save output as csv
gbif_occurrences_sb %>% 
  sf::st_set_geometry(NULL) %>% 
  readr::write_csv("data/gbif_occurrences_sb.csv")
```

## iNaturalist
```{r, include = FALSE, echo = FALSE}
## Extract iNaturalist occurrences for the Dangermond Preserve
inat_occurrence_count_dangermond <- spocc::occ(from = "inat", limit = 1, geometry = dangermond_preserve_bbox, has_coords = TRUE)$inat$meta$found
inat_occurrences_dangermond <- spocc::occ(from = "inat", limit = inat_occurrence_count_dangermond, geometry = dangermond_preserve_bbox, has_coords = TRUE)$inat$data[[1]]
## Remove casual and obscured observations
inat_occurrences_dangermond <- inat_occurrences_dangermond %>%
  dplyr::filter(quality_grade != "casual") %>% 
  dplyr::filter(!(obscured == TRUE & public_positional_accuracy >= 10000))
### Save output as csv
inat_occurrences_dangermond %>% readr::write_csv("data/inat_occurrences_dangermond.csv")

## Extract data from Dangermond Preserve iNaturalist project
inat_occurrences_from_dangermond_project <- rinat::get_inat_obs_project(grpid = "dangermond-preserve-tnc")
### Save output as csv
inat_occurrences_from_dangermond_project %>% readr::write_csv("data/inat_occurrences_from_dangermond_project.csv")


```

## CalFlora
```{r, include = FALSE, echo = FALSE}
## Increase timeout limit
options(timeout = 300)
## Extract CalFlora curated occurrences table for the Dangermond Preserve using RSelenium
### Start the web driver
driver <- RSelenium::rsDriver(browser = "firefox", port = 6020L)
### Say 'I'm a client'
remote_driver <- driver[["client"]]
### Send website address to the browser
calflora_dangermond_url <- "https://www.calflora.org/entry/observ.html#srch=t&cols=0,4,5,2,47,46,3,13,38,1,59,33&lpom=d&chk=t&inbp=t&bgid=psd32678&y=34.505&x=-120.4343&z=11&cch=t&cnabh=t&inat=r"
### Navigate to desired URL
remote_driver$navigate(calflora_dangermond_url)
### Extract page source
page_source <- remote_driver$getPageSource()[[1]] 
### Extract records table
calflora_occurrences_dangermond <- page_source %>% rvest::read_html() %>% rvest::html_elements(xpath = '//div[@id="resultSlot"]') %>% rvest::html_table(header = TRUE)
calflora_occurrences_dangermond <- calflora_occurrences_dangermond[[1]][, -1]
### Save output as csv
calflora_occurrences_dangermond %>% readr::write_csv("data/calflora_occurrences_dangermond.csv")
```

## iDigBio
```{r, include = FALSE, echo = FALSE}
## Extract iDigBio occurrences for the Dangermond Preserve
idigbio_occurrence_count_dangermond <- spocc::occ(from = "idigbio", limit = 1, geometry = dangermond_preserve_bbox)$idigbio$meta$found
idigbio_occurrences_dangermond <- spocc::occ(from = "idigbio", limit = idigbio_occurrence_count_dangermond, geometry = dangermond_preserve_bbox)$idigbio$data[[1]]
### Save output as csv
idigbio_occurrences_dangermond %>% readr::write_csv("data/idigbio_occurrences_dangermond.csv")
```

# Process and Integrate Species Occurrence Data
```{r, include = FALSE, echo = FALSE}
# Reload data if not already loaded
if (!("calflora_occurrences_dangermond" %in% ls())) calflora_occurrences_dangermond <- read_csv("data/calflora_occurrences_dangermond.csv")
if (!("gbif_occurrences_sb" %in% ls())) gbif_occurrences_sb <- read_csv("data/gbif_occurrences_sb.csv")
if (!("inat_occurrences_dangermond" %in% ls())) inat_occurrences_dangermond <- read_csv("data/inat_occurrences_dangermond.csv")
if (!("inat_occurrences_from_dangermond_project" %in% ls())) inat_occurrences_from_dangermond_project <- read_csv("data/inat_occurrences_from_dangermond_project.csv")
if (!("idigbio_occurrences_dangermond" %in% ls())) idigbio_occurrences_dangermond <- read_csv("data/idigbio_occurrences_dangermond.csv")

# Specify minimum set of common fields for integration
data_fields <- c("key", "scientificName", "longitude", "latitude", "coordinateUncertaintyInMeters", "eventDate", "year", "source", "dataset", "URL")

# Process datasets to fit common fields
## CalFlora
### Rename fields
calflora_occurrences_dangermond_clean <- calflora_occurrences_dangermond %>% 
  dplyr::mutate(key = ID, scientificName = Taxon, longitude = Longitude, latitude = Latitude, coordinateUncertaintyInMeters = `Error Radius (m)`, eventDate = Date, year = substr(eventDate, 1, 4), source = "CalFlora", dataset = Source, URL = `Detail URL`) %>% 
  dplyr::select(data_fields) %>% 
  dplyr::mutate(key = as.character(key), eventDate = as.character(eventDate), year = as.numeric(year), longitude = as.numeric(longitude), latitude = as.numeric(latitude))
calflora_occurrences_dangermond_clean$URL <- purrr::map_chr(1:nrow(calflora_occurrences_dangermond_clean), function(i) ifelse(grepl("in:", calflora_occurrences_dangermond_clean$key[i]), paste0("https://www.inaturalist.org/observations/", gsub("in:", "", calflora_occurrences_dangermond_clean$key[i])), calflora_occurrences_dangermond_clean$URL[i]))
calflora_occurrences_dangermond_clean$URL <- purrr::map_chr(calflora_occurrences_dangermond_clean$URL , function(x) ifelse(grepl("entry/occdetail.html", x), paste0("https://www.calflora.org/entry/", x), x))

## GBIF
gbif_occurrences_sb_clean <- gbif_occurrences_sb %>% 
  dplyr::filter(!(institutioncode == "iNaturalist" & decimallongitude >= -120.4993 & decimallongitude <= -120.3577 & decimallatitude >= 34.4423 & decimallatitude <= 34.57419)) %>% # Remove iNaturalist records that overlap the Dangermond bounding box because those are being extracted directly from iNaturalist
  dplyr::mutate(scientificName = verbatimscientificname, longitude = decimallongitude, latitude = decimallatitude, source = "GBIF", dataset = institutioncode, key = gbifid, coordinateUncertaintyInMeters = coordinateuncertaintyinmeters, eventDate = eventdate, URL = paste0("https://www.gbif.org/occurrence/", gbifid), year = year) %>% 
  dplyr::select(data_fields) %>% 
  dplyr::mutate(key = as.character(key), eventDate = as.character(eventDate), year = as.numeric(year), longitude = as.numeric(longitude), latitude = as.numeric(latitude))

## iNaturalist (General Search)
inat_occurrences_dangermond_clean <- inat_occurrences_dangermond %>% 
  dplyr::filter(obscured == FALSE, quality_grade != "casual") %>% 
  dplyr::mutate(key = id, scientificName = name, coordinateUncertaintyInMeters = positional_accuracy, eventDate = observed_on, year = substr(eventDate, 1, 4), source = "iNaturalist", dataset = "iNaturalist", URL = uri) %>% 
  dplyr::select(data_fields) %>% 
  dplyr::mutate(key = as.character(key), eventDate = as.character(eventDate), year = as.numeric(year), longitude = as.numeric(longitude), latitude = as.numeric(latitude))

## iNaturalist (Project Search)
inat_occurrences_from_dangermond_project_cleaned <- inat_occurrences_from_dangermond_project %>%
  dplyr::filter(quality_grade != "casual") %>% 
  dplyr::mutate(key = id, scientificName = taxon.name, coordinateUncertaintyInMeters = positional_accuracy, eventDate = observed_on, year = substr(eventDate, 1, 4), source = "iNaturalist", dataset = "iNaturalist Dangermond Preserve Project", URL = uri) %>% 
  dplyr::select(data_fields) %>% 
  dplyr::mutate(key = as.character(key), eventDate = as.character(eventDate), year = as.numeric(year), longitude = as.numeric(longitude), latitude = as.numeric(latitude))

## iDigBio
idigbio_occurrences_dangermond_cleaned <- idigbio_occurrences_dangermond %>% 
  dplyr::mutate(key = uuid, scientificName = paste0(toupper(substr(canonicalname, 1, 1)), substr(name, 2, nchar(name))), coordinateUncertaintyInMeters = coordinateuncertainty, eventDate = datecollected, year = substr(eventDate, 1, 4), source = "iDigBio", dataset = toupper(institutioncode), URL = paste0("https://www.idigbio.org/portal/records/", key)) %>% 
  dplyr::select(data_fields) %>%
  dplyr::filter(year >= 1980) %>% 
  dplyr::mutate(key = as.character(key), eventDate = as.character(eventDate), year = as.numeric(year), longitude = as.numeric(longitude), latitude = as.numeric(latitude))

# Integrate datasets
integrated_occurrences_dangermond <- list(calflora_occurrences_dangermond_clean,
                               gbif_occurrences_sb_clean,
                               inat_occurrences_dangermond_clean,
                               inat_occurrences_from_dangermond_project_cleaned,
                               idigbio_occurrences_dangermond_cleaned) %>% 
  bind_rows()
```

# Integrate Taxonomic Information
```{r, include = FALSE, echo = FALSE}
# Extract list of unique taxonomic concepts for Dangermond Preserve
dangermond_taxa <- integrated_dangermond_occurrences$scientificName %>% unique()
dangermond_taxa <- dangermond_taxa[-which(dangermond_taxa %in% c(NA, ""))]
# Extract taxonomic information using the Global Name Resolver service accessed via R package Taxize
## Run queries in parallel
taxa_chunks <- split(1:length(dangermond_taxa), ceiling(seq_along(1:length(dangermond_taxa))/1000))
dangermond_taxa_info_gnr_list <- vector("list", length(taxa_chunks))
for (i in 1:length(dangermond_taxa_info_gnr_list)){
  dangermond_taxa_info_gnr_list[[i]] <- purrr::map(dangermond_taxa[taxa_chunks[[i]]], purrr::safely(function(x) taxize::gnr_resolve(x, fields = "all", best_match_only = TRUE, canonical = TRUE, preferred_data_sources = c(11)))
  ) 
}
## Extract taxonomic information from GBIF Backbone Taxonomy
dangermond_taxa_info_gbif <- purrr::map(dangermond_taxa_info_gnr_list, function(x) purrr::map(x, "result") %>% bind_rows()) %>% 
  bind_rows() %>% 
  dplyr::filter(complete.cases(matched_name2),
                classification_path != "") 
dangermond_taxa_info_gbif <- dangermond_taxa_info_gbif %>% 
      dplyr::mutate(kingdom = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "kingdom")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist(),
                    phylum = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "phylum")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist(),
                    class = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "class")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist(),
                    order = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "order")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist(),
                    family = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "family")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist(),
                    genus = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "genus")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist(),
                    species = purrr::map(strsplit(classification_path, "\\|"), which(strsplit(classification_path_ranks[1], "\\|")[[1]] == "species")) %>% purrr::map(function(x) ifelse(!is.null(x), x, NA)) %>% unlist()
                    )
## Write out taxonomic information
dangermond_taxa_info_gbif %>% write_csv("data/dangermond_taxa_info_gbif.csv")

## Bind taxonomic information to occurrences data
integrated_occurrences_dangermond <- integrated_occurrences_dangermond %>% 
  dplyr::left_join(dangermond_taxa_info_gbif %>% dplyr::select(user_supplied_name, matched_name2, classification_path, kingdom, phylum, class, order, family, genus, species), by = c("scientificName" = "user_supplied_name")) %>% 
  dplyr::mutate(scientificName = matched_name2, scientificName_source = scientificName) %>% 
  dplyr::select(-matched_name2)

### Save output as CSV
integrated_occurrences_dangermond %>% readr::write_csv(paste0("data/integrated_occurrences_dangermond.csv"))
```

# Integrate Conservation Status Information
```{r, include = FALSE, echo = FALSE}
# Extract dangermond GBIF taxon names
dangermond_taxa <- integrated_dangermond_occurrences$species %>% unique()
dangermond_taxa <- dangermond_taxa[-which(dangermond_taxa %in% c(NA, ""))]
# Extract NatureServe information on CDFW State Rank, NatureServe Global Rank, US ESA Status, and IUCN Red List Category
dangermond_taxa_conservation_statuses <- purrr::map(dangermond_taxa, function(sp){
  print(paste0(sp, " (", round(which(dangermond_taxa %in% sp)/length(dangermond_taxa), 4), "%)"))
  x <- natserv::ns_search_spp(text_adv = list(searchToken = sp, matchAgainst = "allScientificNames", operator="equals"))$results
  if (nrow(x) > 0){
     y <- natserv::ns_id(uid = x$uniqueId[1])
  out <- data.frame(species = sp,
    California_srank = ifelse(sum((y$elementNationals$elementSubnationals %>% bind_rows())$subnation$nameEn == "California") > 0, (y$elementNationals$elementSubnationals %>% bind_rows())$roundedSRank[which((y$elementNationals$elementSubnationals %>% bind_rows())$subnation$nameEn == "California")], NA),
                    grank = y$roundedGRank,
                    esa = ifelse(!is.null(y$speciesGlobal$usesa), y$speciesGlobal$usesa$usesaDescEn, NA),
                    iucn = ifelse(!is.null(y$iucn), y$iucn$iucnDescEn, NA)
  ) 
  } else {
    out <- data.frame(species = sp,
                      California_srank = NA,
                      grank = NA,
                      esa = NA,
                      iucn = NA
    )
  }
  out
}) %>% 
  bind_rows()
## Bind conservation status information to occurrences data
integrated_occurrences_dangermond <- integrated_occurrences_dangermond %>% 
  dplyr::left_join(dangermond_taxa_conservation_statuses, by = "species")
### Save output as CSV
integrated_occurrences_dangermond %>% readr::write_csv(paste0("data/integrated_occurrences_dangermond.csv"))
```


## Other biodiversity data layers
### DataONE
```{r, include = FALSE, echo = FALSE}
## Function to extract DataONE data
extract_dataone_datasets <- function(query_text = "(attribute:\"Dangermond Preserve\" OR \"Point Conception\" OR \"Santa Barbara\" OR \"Central Coast\" OR \"Santa Ynez\") AND (attribute:\"California\") AND (attribute:\"Species\") AND (attribute:\"Occurrences\" OR \"Distributions\" OR \"Observations\")"){
  # Load library(dataone)
  library(dataone)
  # Identify the CNode object representing the DataONE environment
  cn <- dataone::CNode("PROD")
  # Write while loop to extract all relevant datasets
  ## Create necessary objects
  dataone_datasets_list <- NULL
  batch_size <- 10000
  batch_start <- -10000
  ## Run loop while batch size equals 10000
  while (batch_size == 10000){
    batch_start <- batch_start + batch_size
    # Create list with Solr query parameters
    queryParams <- list(q = query_text,
                        rows = as.character(batch_size),
                        start = as.character(batch_start)
    )
    # Send query to dataone API
    new_datasets <- dataone::query(cn, solrQuery = queryParams, as = "list")
    # Update batch_size
    batch_size <- length(new_datasets)
    # Concatenate datasets list
    dataone_datasets_list <- c(dataone_datasets_list, new_datasets)
  }
  return(dataone_datasets_list)
}
## Extract DataONE data for the Dangermond Preserve
dataone_datasets_dangermond <- extract_dataone_datasets()
## Download DataONE data for the Dangermond Preserve
### Function to download all datasets
download_dataone_datasets <- function(datasets = dataone_datasets_dangermond){
  dataone_dir <- "data/dataone"
  ### Create output folder
  dir.create(dataone_dir)
  ### Identify the CNode object representing the DataONE environment
  cn <- CNode()
  ### Loop through datasets
  purrr::map(datasets, purrr::safely(function(dat){
    ### Identify the member node for each datasets
    mn <- getMNode(cn, dat$authoritativeMN)
    ### Download each dataset based on its id and node
    getPackage(x = mn, id = dat$id, dirPath = dataone_dir, unzip = TRUE)
  })
  )
}
### Download datasets
download_dataone_datasets()
```

### California Departmnet of Fish and Wildlife
```{r, include = FALSE, echo = FALSE}
## Extract list of layers from CDFW ArcGIS REST Service
### Get JSON file from REST Service home
service_json <- jsonlite::fromJSON(paste0("https://services2.arcgis.com/Uq9r85Potqm3MfRV/ArcGIS/rest/services?f=pjson"))
### Identify URLs for relevant layers: ACE and CWHR
service_urls <- service_json$services$url
biosds_urls <- service_urls[grep("biosds", service_urls)]
## Download layers from CDFW ArcGIS REST Service
### Create output directory
dir.create("data/cdfw")
gis_layers <- purrr::map(biosds_urls[500:length(biosds_urls)], purrr::safely(function(u){
  dataset_info <- jsonlite::fromJSON(paste0(u, "?f=pjson"))
  dataset_bbox <- data.frame(
    x = c(dataset_info$fullExtent$xmin, dataset_info$fullExtent$xmax),
    y = c(dataset_info$fullExtent$ymin, dataset_info$fullExtent$ymax)
  ) %>%
    sf::st_as_sf(coords = c("x", "y"), crs = dataset_info$fullExtent$spatialReference$latestWkid) %>%
    sf::st_bbox() %>%
    sf::st_as_sfc() %>% 
    sf::st_transform(crs = sf::st_crs(dangermond_preserve))
  dataset_intersects <- sf::st_intersects(dataset_bbox, dangermond_preserve, sparse = FALSE)[1, 1]
  if (isTRUE(dataset_intersects)){
    layer_names <- dataset_info$layers$id
    layer_data <- purrr::map(layer_names, function(l){
      layer_sf <- esri2sf::esri2sf(paste0(u, "/", l))
      sf::st_write(layer_sf, paste0("data/cdfw/", dataset_info$layers$name, ".shp"))
      layer_sf
    })
  } else {
    NULL
  }
}))
```

### USGS ScienceBase
```{r, include = FALSE, echo = FALSE}
## Extract datasets from USGS ScienceBase using library(sbtools)
library(sbtools)
### Spatial query: included within Dangermond Preserve bounds
sciencebase_datasets_dangermond <- sbtools::query_sb(list(browseCategory = "Data", spatialQuery = '{"wkt": "POLYGON ((-120.4993 34.4423, -120.3577 34.4423, -120.3577 34.57419, -120.4993 34.57419, -120.4993 34.4423))","relation":"within", "fields":"Bounds"}'), limit = 100000)
### Spatial query + tagged "biodiversity"
sciencebase_datasets_dangermond <- sbtools::query_sb(list(tags = "biodiversity", spatialQuery = '{"wkt": "POLYGON ((-120.4993 34.4423, -120.3577 34.4423, -120.3577 34.57419, -120.4993 34.57419, -120.4993 34.4423))","relation":"within", "fields":"Bounds"}'), limit = 100000)
sciencebase_datasets_3counties <- sbtools::query_sb(list(q = "Species", spatialQuery = '{"wkt": "POLYGON ((-121.3464 33.21473, -118.6325 33.21473, -118.6325 35.79518, -121.3464 35.79518, -121.3464 33.21473))","relation":"within", "fields":"Bounds"}'), limit = 100000)
## Download datasets from USGS ScienceBase
dir.create("data/sciencebase")
purrr::map(1:length(sciencebase_datasets_3counties), function(i){
  dataset_endpoint <- paste0("https://www.sciencebase.gov/catalog/file/get/", sciencebase_datasets_3counties[[i]]$id)
  download.file(dataset_endpoint, destfile = paste0("data/sciencebase/", sciencebase_datasets_3counties[[i]]$title))
})
```

### Data.gov
```{r, include = FALSE, echo = FALSE}
## Extract datasets from Data.gov
### Set up query
datagov_query <- "q=Santa+Barbara+AND+California+AND+Species+occurrences&metadata_type:geospatial"
datagov_datasets_count <- jsonlite::fromJSON(paste0("https://catalog.data.gov/api/3/action/package_search?", datagov_query))$result$count
datagov_pages <- ceiling(datagov_datasets_count/1000)-1
datagov_datasets <- purrr::map(0:datagov_pages, function(p){
  datagov_start <- 0+(p*1000)
  datagov_datasets <- jsonlite::fromJSON(paste0("https://catalog.data.gov/api/3/action/package_search?", datagov_query, datagov_start))
})
```
